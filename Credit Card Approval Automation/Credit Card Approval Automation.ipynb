{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the relevant packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, balanced_accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('train_data.csv',index_col=0)\n",
    "test_data = pd.read_csv('test_data.csv',index_col=0)\n",
    "train_data.index = range(len(train_data))\n",
    "train_data.loc[train_data['OCCUPATION']!=1,'OCCUPATION'] = 0\n",
    "test_data.index = range(len(test_data))\n",
    "test_data.loc[test_data['OCCUPATION']!=1,'OCCUPATION'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepping data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, we list all the categorical variables to be one hot encoded\n",
    "cat_vars = ['MARRIAGE', 'EDUCATION']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an encoder for each cat_vars\n",
    "encoders = [OneHotEncoder(categories='auto') for _ in range(len(cat_vars))] \n",
    "# encode each of the cat_vars with their respective encoder\n",
    "encoded_tr = [encoders[i].fit_transform(train_data[[cat_var]]).todense() for i,cat_var in enumerate(cat_vars)]\n",
    "encoded_test = [encoders[i].fit_transform(test_data[[cat_var]]).todense() for i,cat_var in enumerate(cat_vars)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the label column and also drop the cat_vars \n",
    "# this way we can combine the encoded categorical variables with the continuous variables \n",
    "X_train = pd.concat([train_data.iloc[:,:-1].drop(cat_vars, axis=1), \n",
    "                     pd.DataFrame(np.concatenate(encoded_tr, axis=1))], axis=1)\n",
    "X_test = pd.concat([test_data.iloc[:,:-1].drop(cat_vars, axis=1), \n",
    "                    pd.DataFrame(np.concatenate(encoded_test, axis=1))], axis=1)\n",
    "y_train = train_data.iloc[:,-1] \n",
    "y_test = test_data.iloc[:,-1]\n",
    "X_train = X_train.rename(columns={0:'Marriage 1',1:'Marriage 2',2:'Marriage 3',3:'Edu 1',4:'Edu 2',5:'Edu 3',\n",
    "                                  6:'Edu 4',7:'Edu 5',8:'Edu 6',9:'Edu 7'})\n",
    "# Note that in the testing data, we do not have Marriage 3 and Edu 6\n",
    "X_test = X_test.rename(columns={0:'Marriage 1',1:'Marriage 2',2:'Edu 1',3:'Edu 2',4:'Edu 3',\n",
    "                                  5:'Edu 4',6:'Edu 5',7:'Edu 7'})\n",
    "X_train = X_train.astype('float64')\n",
    "X_test = X_test.astype('float64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize continuous features. Note that for the testing data, we still use the mean and standard deviation from the training data to do the normalization.Â¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [0,1,2,3,4,5,8]:\n",
    "    X1 = X_train.iloc[:,i]\n",
    "    mean = X1.mean()\n",
    "    std = X1.std()\n",
    "    X_train.iloc[:,i] = (X1-mean)/std\n",
    "    X_test.iloc[:,i] = (X_test.iloc[:,i]-mean)/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rid of some dummy variables to avoid perfect multicollinearity\n",
    "X_train = X_train.drop(['Marriage 3','Edu 6'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DEBT</th>\n",
       "      <th>YRS_IN_RESIDENT</th>\n",
       "      <th>AGE</th>\n",
       "      <th>YRS_OF_EMPLOYMENT</th>\n",
       "      <th>DTI</th>\n",
       "      <th>NUM_PREV_APP</th>\n",
       "      <th>OCCUPATION</th>\n",
       "      <th>PROVIDED_SIN</th>\n",
       "      <th>INCOME</th>\n",
       "      <th>CREDIT_PROFILE</th>\n",
       "      <th>Marriage 1</th>\n",
       "      <th>Marriage 2</th>\n",
       "      <th>Edu 1</th>\n",
       "      <th>Edu 2</th>\n",
       "      <th>Edu 3</th>\n",
       "      <th>Edu 4</th>\n",
       "      <th>Edu 5</th>\n",
       "      <th>Edu 7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.835945</td>\n",
       "      <td>-0.686741</td>\n",
       "      <td>-1.085931</td>\n",
       "      <td>-0.642788</td>\n",
       "      <td>-0.074637</td>\n",
       "      <td>-0.555121</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.530698</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.294264</td>\n",
       "      <td>-1.364851</td>\n",
       "      <td>1.314706</td>\n",
       "      <td>-0.095677</td>\n",
       "      <td>-0.630176</td>\n",
       "      <td>-0.555121</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.109336</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.072081</td>\n",
       "      <td>-1.025796</td>\n",
       "      <td>0.238559</td>\n",
       "      <td>-0.045939</td>\n",
       "      <td>1.036440</td>\n",
       "      <td>-0.555121</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.804037</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.233465</td>\n",
       "      <td>-0.347686</td>\n",
       "      <td>-1.003150</td>\n",
       "      <td>-0.841738</td>\n",
       "      <td>-0.667212</td>\n",
       "      <td>0.153818</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.749370</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.309851</td>\n",
       "      <td>1.008535</td>\n",
       "      <td>1.066364</td>\n",
       "      <td>0.451435</td>\n",
       "      <td>-0.185745</td>\n",
       "      <td>-0.555121</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.164003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       DEBT  YRS_IN_RESIDENT       AGE  YRS_OF_EMPLOYMENT       DTI  \\\n",
       "0  0.835945        -0.686741 -1.085931          -0.642788 -0.074637   \n",
       "1  1.294264        -1.364851  1.314706          -0.095677 -0.630176   \n",
       "2  0.072081        -1.025796  0.238559          -0.045939  1.036440   \n",
       "3 -0.233465        -0.347686 -1.003150          -0.841738 -0.667212   \n",
       "4 -0.309851         1.008535  1.066364           0.451435 -0.185745   \n",
       "\n",
       "   NUM_PREV_APP  OCCUPATION  PROVIDED_SIN    INCOME  CREDIT_PROFILE  \\\n",
       "0     -0.555121         0.0           1.0  1.530698             1.0   \n",
       "1     -0.555121         1.0           1.0 -0.109336             1.0   \n",
       "2     -0.555121         1.0           1.0  1.804037             0.0   \n",
       "3      0.153818         0.0           1.0 -1.749370             0.0   \n",
       "4     -0.555121         0.0           1.0  0.164003             0.0   \n",
       "\n",
       "   Marriage 1  Marriage 2  Edu 1  Edu 2  Edu 3  Edu 4  Edu 5  Edu 7  \n",
       "0         1.0         0.0    0.0    0.0    0.0    1.0    0.0    0.0  \n",
       "1         0.0         1.0    0.0    0.0    0.0    1.0    0.0    0.0  \n",
       "2         0.0         1.0    0.0    0.0    0.0    0.0    0.0    1.0  \n",
       "3         0.0         1.0    1.0    0.0    0.0    0.0    0.0    0.0  \n",
       "4         1.0         0.0    0.0    0.0    0.0    1.0    0.0    0.0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DEBT</th>\n",
       "      <th>YRS_IN_RESIDENT</th>\n",
       "      <th>AGE</th>\n",
       "      <th>YRS_OF_EMPLOYMENT</th>\n",
       "      <th>DTI</th>\n",
       "      <th>NUM_PREV_APP</th>\n",
       "      <th>OCCUPATION</th>\n",
       "      <th>PROVIDED_SIN</th>\n",
       "      <th>INCOME</th>\n",
       "      <th>CREDIT_PROFILE</th>\n",
       "      <th>Marriage 1</th>\n",
       "      <th>Marriage 2</th>\n",
       "      <th>Edu 1</th>\n",
       "      <th>Edu 2</th>\n",
       "      <th>Edu 3</th>\n",
       "      <th>Edu 4</th>\n",
       "      <th>Edu 5</th>\n",
       "      <th>Edu 7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.233465</td>\n",
       "      <td>-1.364851</td>\n",
       "      <td>-0.672028</td>\n",
       "      <td>0.351960</td>\n",
       "      <td>0.962368</td>\n",
       "      <td>-0.555121</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.476031</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.683172</td>\n",
       "      <td>-0.008630</td>\n",
       "      <td>0.735242</td>\n",
       "      <td>0.053536</td>\n",
       "      <td>0.814224</td>\n",
       "      <td>0.862758</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.984020</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.309851</td>\n",
       "      <td>-0.347686</td>\n",
       "      <td>-1.168711</td>\n",
       "      <td>-0.941213</td>\n",
       "      <td>-0.667212</td>\n",
       "      <td>-0.555121</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.656014</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.189971</td>\n",
       "      <td>1.008535</td>\n",
       "      <td>0.321339</td>\n",
       "      <td>-0.742263</td>\n",
       "      <td>-0.444997</td>\n",
       "      <td>0.390132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.382675</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.157078</td>\n",
       "      <td>1.347590</td>\n",
       "      <td>0.486900</td>\n",
       "      <td>1.048284</td>\n",
       "      <td>0.073506</td>\n",
       "      <td>0.862758</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.804037</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       DEBT  YRS_IN_RESIDENT       AGE  YRS_OF_EMPLOYMENT       DTI  \\\n",
       "0 -0.233465        -1.364851 -0.672028           0.351960  0.962368   \n",
       "1  0.683172        -0.008630  0.735242           0.053536  0.814224   \n",
       "2 -0.309851        -0.347686 -1.168711          -0.941213 -0.667212   \n",
       "3  5.189971         1.008535  0.321339          -0.742263 -0.444997   \n",
       "4 -0.157078         1.347590  0.486900           1.048284  0.073506   \n",
       "\n",
       "   NUM_PREV_APP  OCCUPATION  PROVIDED_SIN    INCOME  CREDIT_PROFILE  \\\n",
       "0     -0.555121         1.0           1.0 -1.476031             1.0   \n",
       "1      0.862758         1.0           1.0  0.984020             1.0   \n",
       "2     -0.555121         1.0           0.0 -0.656014             0.0   \n",
       "3      0.390132         0.0           0.0 -0.382675             1.0   \n",
       "4      0.862758         0.0           1.0  1.804037             1.0   \n",
       "\n",
       "   Marriage 1  Marriage 2  Edu 1  Edu 2  Edu 3  Edu 4  Edu 5  Edu 7  \n",
       "0         1.0         0.0    0.0    0.0    0.0    1.0    0.0    0.0  \n",
       "1         0.0         1.0    0.0    0.0    0.0    0.0    0.0    1.0  \n",
       "2         1.0         0.0    1.0    0.0    0.0    0.0    0.0    0.0  \n",
       "3         0.0         1.0    0.0    0.0    0.0    1.0    0.0    0.0  \n",
       "4         0.0         1.0    0.0    0.0    0.0    1.0    0.0    0.0  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our first task is to see if the dataset has class imbalance.  In our case, the number of approvals and rejections are roughly the same in the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "APPROVAL_STATUS\n",
       "0    300\n",
       "1    250\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import a number of classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### For GirdSearchCV, the default scoring for classifier is accuracy, which seems to be a reasonable choice in our problem given that the data does not have serious imbalance problem. In case there is a serious imbalance problem, then other socring choice maybe more appropriate. These include:\n",
    "### (1) Balanced accuracy\n",
    "The balanced accuracy is the average between the sensitivity (true positive rate, or recall) and the specificity (true negative rate), \n",
    "which measures the \n",
    "average accuracy obtained from both the minority and majority classes. This quantity reduces to the\r\n",
    "tradition\n",
    "l accuracy if a classifier performs equally well on either classes. Conversely, if the high value o \r\n",
    "the traditional accuracy is due\n",
    "to the classifier taking advantage of the distribution of the majority clas, \r\n",
    "then the balanced accuracy will decrease compared to the accu.y\n",
    "### (2) F1-ratio\n",
    "F1-ratio is the harmonic mean of precision and recall, i.e., F1-ratio = 2/(1/precision+1/recall).  In scenarios where the dataset is imbalanced, using the F1-ratio helps mitigate biased evaluations. Since the F1-ratio accounts for both precision and recall, it cam provide a more fair assessment of the model's performance as compared with the accuracy score.\n",
    "\n",
    "Finally, the cost of type I and type II errors maybe different.  In that case, we need to have more explicit objective on what we try to maximize.  For example, if we want to maximize TP-4*FP, we can define a custom scoring function by using make_scorer.  In the following, we stay with the default scoring option of accuracy.ðð¡ð¦) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1: LDA, the only tuning parameter is shrinkage, we first use the default option, and then use the GridSearchCV to find the best shrinkage paramter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: LDA (default)\n",
      "Accuracy Score on Training Data = 0.8600\n",
      "Performance on Testing Data:\n",
      "Accuracy Score = 0.8714\n",
      "Balanced Accuracy Socre = 0.8723\n",
      "True Positive Rate = 0.8772\n",
      "True Negative Rate = 0.8675\n",
      "Precision = 0.8197\n",
      "F1-score = 0.8475\n",
      "AUC = 0.9269\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = LinearDiscriminantAnalysis()\n",
    "model.fit(X_train,y_train)\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "train_accuracy = accuracy_score(y_train,y_train_pred)\n",
    "test_accuracy = accuracy_score(y_test,y_test_pred)\n",
    "bal_accuracy = balanced_accuracy_score(y_test, y_test_pred)\n",
    "TN, FP, FN, TP = confusion_matrix(y_test,y_test_pred,sample_weight=None).ravel()\n",
    "TPR = recall_score(y_test, y_test_pred)   # Sensitivity = TP/(TP+FN)\n",
    "TNR = TN/(TN+FP)                          # Specificity\n",
    "Precision = precision_score(y_test, y_test_pred)\n",
    "F1score = f1_score(y_test, y_test_pred)\n",
    "Q = model.predict_proba(X_test)[:,1]\n",
    "fpr, tpr, _ = roc_curve(y_test, Q)\n",
    "roc_auc = auc(fpr,tpr)    \n",
    "print(\"Classifier: LDA (default)\")    \n",
    "print(\"Accuracy Score on Training Data = {:.4f}\".format(train_accuracy))    \n",
    "print(\"Performance on Testing Data:\")\n",
    "print(\"Accuracy Score = {:.4f}\".format(test_accuracy))\n",
    "print(\"Balanced Accuracy Socre = {:.4f}\".format(bal_accuracy))\n",
    "print(\"True Positive Rate = {:.4f}\".format(TPR))\n",
    "print(\"True Negative Rate = {:.4f}\".format(TNR))\n",
    "print(\"Precision = {:.4f}\".format(Precision))\n",
    "print(\"F1-score = {:.4f}\".format(F1score))\n",
    "print(\"AUC = {:.4f}\\n\".format(roc_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Shrinkage Parameter = 0.3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = LinearDiscriminantAnalysis(solver='lsqr')\n",
    "param_grid = {'shrinkage': np.linspace(0,1,11)}\n",
    "clf_lda = GridSearchCV(model, param_grid, cv=3, n_jobs=-1)\n",
    "clf_lda.fit(X_train,y_train)\n",
    "clf_reg_params = clf_lda.best_params_['shrinkage']\n",
    "print(\"Best Shrinkage Parameter = {:.4f}\\n\".format(clf_reg_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: LDA (shrinkage parameter based on 3-fold CV)\n",
      "Accuracy Score on Training Data = 0.8673\n",
      "Performance on Testing Data:\n",
      "Accuracy Score = 0.8929\n",
      "Balanced Accuracy Socre = 0.8849\n",
      "True Positive Rate = 0.8421\n",
      "True Negative Rate = 0.9277\n",
      "Precision = 0.8889\n",
      "F1-score = 0.8649\n",
      "AUC = 0.9334\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = LinearDiscriminantAnalysis(solver='lsqr',shrinkage=clf_reg_params)\n",
    "model.fit(X_train,y_train)\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "train_accuracy = accuracy_score(y_train,y_train_pred)\n",
    "test_accuracy = accuracy_score(y_test,y_test_pred)\n",
    "bal_accuracy = balanced_accuracy_score(y_test, y_test_pred)\n",
    "TN, FP, FN, TP = confusion_matrix(y_test,y_test_pred,sample_weight=None).ravel()\n",
    "TPR = recall_score(y_test, y_test_pred)   # Sensitivity = TP/(TP+FN)\n",
    "TNR = TN/(TN+FP)                          # Specificity\n",
    "Precision = precision_score(y_test, y_test_pred)\n",
    "F1score = f1_score(y_test, y_test_pred)\n",
    "Q = model.predict_proba(X_test)[:,1]\n",
    "fpr, tpr, _ = roc_curve(y_test, Q)\n",
    "roc_auc = auc(fpr,tpr)    \n",
    "print(\"Classifier: LDA (shrinkage parameter based on 3-fold CV)\")    \n",
    "print(\"Accuracy Score on Training Data = {:.4f}\".format(train_accuracy))    \n",
    "print(\"Performance on Testing Data:\")\n",
    "print(\"Accuracy Score = {:.4f}\".format(test_accuracy))\n",
    "print(\"Balanced Accuracy Socre = {:.4f}\".format(bal_accuracy))\n",
    "print(\"True Positive Rate = {:.4f}\".format(TPR))\n",
    "print(\"True Negative Rate = {:.4f}\".format(TNR))\n",
    "print(\"Precision = {:.4f}\".format(Precision))\n",
    "print(\"F1-score = {:.4f}\".format(F1score))\n",
    "print(\"AUC = {:.4f}\\n\".format(roc_auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2: Logistic regression, we first try the default option, i.e., penalty='l2', C=1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: Logistic Regression (default)\n",
      "Accuracy Score on Training Data = 0.8691\n",
      "Performance on Testing Data:\n",
      "Accuracy Score = 0.8643\n",
      "Balanced Accuracy Socre = 0.8636\n",
      "True Positive Rate = 0.8596\n",
      "True Negative Rate = 0.8675\n",
      "Precision = 0.8167\n",
      "F1-score = 0.8376\n",
      "AUC = 0.9302\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X_train,y_train)\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "train_accuracy = accuracy_score(y_train,y_train_pred)\n",
    "test_accuracy = accuracy_score(y_test,y_test_pred)\n",
    "bal_accuracy = balanced_accuracy_score(y_test, y_test_pred)\n",
    "TN, FP, FN, TP = confusion_matrix(y_test,y_test_pred,sample_weight=None).ravel()\n",
    "TPR = recall_score(y_test, y_test_pred)   # Sensitivity = TP/(TP+FN)\n",
    "TNR = TN/(TN+FP)                          # Specificity\n",
    "Precision = precision_score(y_test, y_test_pred)\n",
    "F1score = f1_score(y_test, y_test_pred)\n",
    "Q = model.predict_proba(X_test)[:,1]\n",
    "fpr, tpr, _ = roc_curve(y_test, Q)\n",
    "roc_auc = auc(fpr,tpr)    \n",
    "print(\"Classifier: Logistic Regression (default)\")    \n",
    "print(\"Accuracy Score on Training Data = {:.4f}\".format(train_accuracy))    \n",
    "print(\"Performance on Testing Data:\")\n",
    "print(\"Accuracy Score = {:.4f}\".format(test_accuracy))\n",
    "print(\"Balanced Accuracy Socre = {:.4f}\".format(bal_accuracy))\n",
    "print(\"True Positive Rate = {:.4f}\".format(TPR))\n",
    "print(\"True Negative Rate = {:.4f}\".format(TNR))\n",
    "print(\"Precision = {:.4f}\".format(Precision))\n",
    "print(\"F1-score = {:.4f}\".format(F1score))\n",
    "print(\"AUC = {:.4f}\\n\".format(roc_auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We now use GridSearchCV to find the best C for the L2-penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best regularization parameter = 0.260\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(penalty='l2')\n",
    "param_grid = {'C': np.linspace(0.01,10,1000)}\n",
    "clf_lgr = GridSearchCV(model, param_grid, n_jobs=-1, cv=3)\n",
    "clf_lgr.fit(X_train, y_train)\n",
    "clf_reg_params = clf_lgr.best_params_['C']\n",
    "print(\"Best regularization parameter = {:.3f}\\n\".format(clf_reg_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: Logistic Regression (L2 penalty parameter based on 3-fold CV)\n",
      "Accuracy Score on Training Data = 0.8709\n",
      "Performance on Testing Data:\n",
      "Accuracy Score = 0.8786\n",
      "Balanced Accuracy Socre = 0.8756\n",
      "True Positive Rate = 0.8596\n",
      "True Negative Rate = 0.8916\n",
      "Precision = 0.8448\n",
      "F1-score = 0.8522\n",
      "AUC = 0.9319\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(penalty='l2',C=clf_reg_params)\n",
    "model.fit(X_train,y_train)\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "train_accuracy = accuracy_score(y_train,y_train_pred)\n",
    "test_accuracy = accuracy_score(y_test,y_test_pred)\n",
    "bal_accuracy = balanced_accuracy_score(y_test, y_test_pred)\n",
    "TN, FP, FN, TP = confusion_matrix(y_test,y_test_pred,sample_weight=None).ravel()\n",
    "TPR = recall_score(y_test, y_test_pred)   # Sensitivity = TP/(TP+FN)\n",
    "TNR = TN/(TN+FP)                          # Specificity\n",
    "Precision = precision_score(y_test, y_test_pred)\n",
    "F1score = f1_score(y_test, y_test_pred)\n",
    "Q = model.predict_proba(X_test)[:,1]\n",
    "fpr, tpr, _ = roc_curve(y_test, Q)\n",
    "roc_auc = auc(fpr,tpr)    \n",
    "print(\"Classifier: Logistic Regression (L2 penalty parameter based on 3-fold CV)\")    \n",
    "print(\"Accuracy Score on Training Data = {:.4f}\".format(train_accuracy))    \n",
    "print(\"Performance on Testing Data:\")\n",
    "print(\"Accuracy Score = {:.4f}\".format(test_accuracy))\n",
    "print(\"Balanced Accuracy Socre = {:.4f}\".format(bal_accuracy))\n",
    "print(\"True Positive Rate = {:.4f}\".format(TPR))\n",
    "print(\"True Negative Rate = {:.4f}\".format(TNR))\n",
    "print(\"Precision = {:.4f}\".format(Precision))\n",
    "print(\"F1-score = {:.4f}\".format(F1score))\n",
    "print(\"AUC = {:.4f}\\n\".format(roc_auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We now repeat the exercise using L1 penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best regularization parameter = 1.650\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(solver='liblinear',penalty='l1')\n",
    "param_grid = {'C': np.linspace(0.05,5,100)}\n",
    "clf_lgr = GridSearchCV(model, param_grid, n_jobs=-1, cv=3)\n",
    "clf_lgr.fit(X_train, y_train)\n",
    "clf_reg_params = clf_lgr.best_params_['C']\n",
    "print(\"Best regularization parameter = {:.3f}\\n\".format(clf_reg_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: Logistic Regression (L1 penalty parameter based on 3-fold CV)\n",
      "Accuracy Score on Training Data = 0.8727\n",
      "Performance on Testing Data:\n",
      "Accuracy Score = 0.8571\n",
      "Balanced Accuracy Socre = 0.8575\n",
      "True Positive Rate = 0.8596\n",
      "True Negative Rate = 0.8554\n",
      "Precision = 0.8033\n",
      "F1-score = 0.8305\n",
      "AUC = 0.9332\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(solver='liblinear',penalty='l1',C=clf_reg_params)\n",
    "model.fit(X_train,y_train)\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "train_accuracy = accuracy_score(y_train,y_train_pred)\n",
    "test_accuracy = accuracy_score(y_test,y_test_pred)\n",
    "bal_accuracy = balanced_accuracy_score(y_test, y_test_pred)\n",
    "TN, FP, FN, TP = confusion_matrix(y_test,y_test_pred,sample_weight=None).ravel()\n",
    "TPR = recall_score(y_test, y_test_pred)   # Sensitivity = TP/(TP+FN)\n",
    "TNR = TN/(TN+FP)                          # Specificity\n",
    "Precision = precision_score(y_test, y_test_pred)\n",
    "F1score = f1_score(y_test, y_test_pred)\n",
    "Q = model.predict_proba(X_test)[:,1]\n",
    "fpr, tpr, _ = roc_curve(y_test, Q)\n",
    "roc_auc = auc(fpr,tpr)    \n",
    "print(\"Classifier: Logistic Regression (L1 penalty parameter based on 3-fold CV)\")    \n",
    "print(\"Accuracy Score on Training Data = {:.4f}\".format(train_accuracy))    \n",
    "print(\"Performance on Testing Data:\")\n",
    "print(\"Accuracy Score = {:.4f}\".format(test_accuracy))\n",
    "print(\"Balanced Accuracy Socre = {:.4f}\".format(bal_accuracy))\n",
    "print(\"True Positive Rate = {:.4f}\".format(TPR))\n",
    "print(\"True Negative Rate = {:.4f}\".format(TNR))\n",
    "print(\"Precision = {:.4f}\".format(Precision))\n",
    "print(\"F1-score = {:.4f}\".format(F1score))\n",
    "print(\"AUC = {:.4f}\\n\".format(roc_auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3: K nearest neighbors, we first try the default option, i.e., n_neighbors=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: KNN (default)\n",
      "Accuracy Score on Training Data = 0.8582\n",
      "Performance on Testing Data:\n",
      "Accuracy Score = 0.8643\n",
      "Balanced Accuracy Socre = 0.8526\n",
      "True Positive Rate = 0.7895\n",
      "True Negative Rate = 0.9157\n",
      "Precision = 0.8654\n",
      "F1-score = 0.8257\n",
      "AUC = 0.9195\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = KNeighborsClassifier()\n",
    "model.fit(X_train,y_train)\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "train_accuracy = accuracy_score(y_train,y_train_pred)\n",
    "test_accuracy = accuracy_score(y_test,y_test_pred)\n",
    "bal_accuracy = balanced_accuracy_score(y_test, y_test_pred)\n",
    "TN, FP, FN, TP = confusion_matrix(y_test,y_test_pred,sample_weight=None).ravel()\n",
    "TPR = recall_score(y_test, y_test_pred)   # Sensitivity = TP/(TP+FN)\n",
    "TNR = TN/(TN+FP)                          # Specificity\n",
    "Precision = precision_score(y_test, y_test_pred)\n",
    "F1score = f1_score(y_test, y_test_pred)\n",
    "Q = model.predict_proba(X_test)[:,1]\n",
    "fpr, tpr, _ = roc_curve(y_test, Q)\n",
    "roc_auc = auc(fpr,tpr)    \n",
    "print(\"Classifier: KNN (default)\")    \n",
    "print(\"Accuracy Score on Training Data = {:.4f}\".format(train_accuracy))    \n",
    "print(\"Performance on Testing Data:\")\n",
    "print(\"Accuracy Score = {:.4f}\".format(test_accuracy))\n",
    "print(\"Balanced Accuracy Socre = {:.4f}\".format(bal_accuracy))\n",
    "print(\"True Positive Rate = {:.4f}\".format(TPR))\n",
    "print(\"True Negative Rate = {:.4f}\".format(TNR))\n",
    "print(\"Precision = {:.4f}\".format(Precision))\n",
    "print(\"F1-score = {:.4f}\".format(F1score))\n",
    "print(\"AUC = {:.4f}\\n\".format(roc_auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We now use GridSearchCV to search for the best tuning parameters n_neighbors.  There are other things that we can tune as well, like metric and weights, but the most important one is the number of neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best number of neighbors = 7\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = KNeighborsClassifier()\n",
    "param_grid = {'n_neighbors': range(1,11)}\n",
    "clf_knn = GridSearchCV(model, param_grid, n_jobs=-1, cv=3)\n",
    "clf_knn.fit(X_train, y_train)\n",
    "clf_knn_params = clf_knn.best_params_['n_neighbors']\n",
    "print(\"Best number of neighbors = {:.0f}\\n\".format(clf_knn_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: KNN (Number of Neighbors based on 3-fold CV)\n",
      "Accuracy Score on Training Data = 0.8691\n",
      "Performance on Testing Data:\n",
      "Accuracy Score = 0.8714\n",
      "Balanced Accuracy Socre = 0.8613\n",
      "True Positive Rate = 0.8070\n",
      "True Negative Rate = 0.9157\n",
      "Precision = 0.8679\n",
      "F1-score = 0.8364\n",
      "AUC = 0.9130\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = KNeighborsClassifier(n_neighbors=clf_knn_params)\n",
    "model.fit(X_train,y_train)\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "train_accuracy = accuracy_score(y_train,y_train_pred)\n",
    "test_accuracy = accuracy_score(y_test,y_test_pred)\n",
    "bal_accuracy = balanced_accuracy_score(y_test, y_test_pred)\n",
    "TN, FP, FN, TP = confusion_matrix(y_test,y_test_pred,sample_weight=None).ravel()\n",
    "TPR = recall_score(y_test, y_test_pred)   # Sensitivity = TP/(TP+FN)\n",
    "TNR = TN/(TN+FP)                          # Specificity\n",
    "Precision = precision_score(y_test, y_test_pred)\n",
    "F1score = f1_score(y_test, y_test_pred)\n",
    "Q = model.predict_proba(X_test)[:,1]\n",
    "fpr, tpr, _ = roc_curve(y_test, Q)\n",
    "roc_auc = auc(fpr,tpr)    \n",
    "print(\"Classifier: KNN (Number of Neighbors based on )\")    \n",
    "print(\"Accuracy Score on Training Data = {:.4f}\".format(train_accuracy))    \n",
    "print(\"Performance on Testing Data:\")\n",
    "print(\"Accuracy Score = {:.4f}\".format(test_accuracy))\n",
    "print(\"Balanced Accuracy Socre = {:.4f}\".format(bal_accuracy))\n",
    "print(\"True Positive Rate = {:.4f}\".format(TPR))\n",
    "print(\"True Negative Rate = {:.4f}\".format(TNR))\n",
    "print(\"Precision = {:.4f}\".format(Precision))\n",
    "print(\"F1-score = {:.4f}\".format(F1score))\n",
    "print(\"AUC = {:.4f}\\n\".format(roc_auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 4: Decision Tree Classifier, we first try the default option, i.e., criterion=gini, max_depth=None, min_samples_split=2, min_samples_leaf=1, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: Decision Tree (default)\n",
      "Accuracy Score on Training Data = 1.0000\n",
      "Performance on Testing Data:\n",
      "Accuracy Score = 0.8571\n",
      "Balanced Accuracy Socre = 0.8438\n",
      "True Positive Rate = 0.7719\n",
      "True Negative Rate = 0.9157\n",
      "Precision = 0.8627\n",
      "F1-score = 0.8148\n",
      "AUC = 0.8438\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = DecisionTreeClassifier()\n",
    "model.fit(X_train,y_train)\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "train_accuracy = accuracy_score(y_train,y_train_pred)\n",
    "test_accuracy = accuracy_score(y_test,y_test_pred)\n",
    "bal_accuracy = balanced_accuracy_score(y_test, y_test_pred)\n",
    "TN, FP, FN, TP = confusion_matrix(y_test,y_test_pred,sample_weight=None).ravel()\n",
    "TPR = recall_score(y_test, y_test_pred)   # Sensitivity = TP/(TP+FN)\n",
    "TNR = TN/(TN+FP)                          # Specificity\n",
    "Precision = precision_score(y_test, y_test_pred)\n",
    "F1score = f1_score(y_test, y_test_pred)\n",
    "Q = model.predict_proba(X_test)[:,1]\n",
    "fpr, tpr, _ = roc_curve(y_test, Q)\n",
    "roc_auc = auc(fpr,tpr)    \n",
    "print(\"Classifier: Decision Tree (default)\")    \n",
    "print(\"Accuracy Score on Training Data = {:.4f}\".format(train_accuracy))    \n",
    "print(\"Performance on Testing Data:\")\n",
    "print(\"Accuracy Score = {:.4f}\".format(test_accuracy))\n",
    "print(\"Balanced Accuracy Socre = {:.4f}\".format(bal_accuracy))\n",
    "print(\"True Positive Rate = {:.4f}\".format(TPR))\n",
    "print(\"True Negative Rate = {:.4f}\".format(TNR))\n",
    "print(\"Precision = {:.4f}\".format(Precision))\n",
    "print(\"F1-score = {:.4f}\".format(F1score))\n",
    "print(\"AUC = {:.4f}\\n\".format(roc_auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We now try to tune the decision based on: (1) max_depth, (2) min_samples_split, and (3) min_samples_leaf.  There are other options that we can tune as well but it will take longer to try all combinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Max Depth = 7\n",
      "Best Min Samples Split = 20\n",
      "Best Min Samples Leaf = 5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = DecisionTreeClassifier()\n",
    "param_grid = {'max_depth': range(3,13),\n",
    "              'min_samples_split': [10,20,30,40,50],\n",
    "              'min_samples_leaf': [1,5,10,15,20]}\n",
    "clf_dt = GridSearchCV(model, param_grid, n_jobs=-1, cv=3)\n",
    "clf_dt.fit(X_train, y_train)\n",
    "clf_dt_param1 = clf_dt.best_params_['max_depth']\n",
    "clf_dt_param2 = clf_dt.best_params_['min_samples_split']\n",
    "clf_dt_param3 = clf_dt.best_params_['min_samples_leaf']\n",
    "print(\"Best Max Depth = {:.0f}\".format(clf_dt_param1))\n",
    "print(\"Best Min Samples Split = {:.0f}\".format(clf_dt_param2))\n",
    "print(\"Best Min Samples Leaf = {:.0f}\\n\".format(clf_dt_param3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: Decision Tree (tuning parameters based on 3-fold CV)\n",
      "Accuracy Score on Training Data = 0.8873\n",
      "Performance on Testing Data:\n",
      "Accuracy Score = 0.8857\n",
      "Balanced Accuracy Socre = 0.8789\n",
      "True Positive Rate = 0.8421\n",
      "True Negative Rate = 0.9157\n",
      "Precision = 0.8727\n",
      "F1-score = 0.8571\n",
      "AUC = 0.9211\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = DecisionTreeClassifier(max_depth=clf_dt_param1,\n",
    "                               min_samples_split=clf_dt_param2,\n",
    "                               min_samples_leaf=clf_dt_param3)\n",
    "model.fit(X_train,y_train)\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "train_accuracy = accuracy_score(y_train,y_train_pred)\n",
    "test_accuracy = accuracy_score(y_test,y_test_pred)\n",
    "bal_accuracy = balanced_accuracy_score(y_test, y_test_pred)\n",
    "TN, FP, FN, TP = confusion_matrix(y_test,y_test_pred,sample_weight=None).ravel()\n",
    "TPR = recall_score(y_test, y_test_pred)   # Sensitivity = TP/(TP+FN)\n",
    "TNR = TN/(TN+FP)                          # Specificity\n",
    "Precision = precision_score(y_test, y_test_pred)\n",
    "F1score = f1_score(y_test, y_test_pred)\n",
    "Q = model.predict_proba(X_test)[:,1]\n",
    "fpr, tpr, _ = roc_curve(y_test, Q)\n",
    "roc_auc = auc(fpr,tpr)    \n",
    "print(\"Classifier: Decision Tree (tuning parameters based on 3-fold CV)\")    \n",
    "print(\"Accuracy Score on Training Data = {:.4f}\".format(train_accuracy))    \n",
    "print(\"Performance on Testing Data:\")\n",
    "print(\"Accuracy Score = {:.4f}\".format(test_accuracy))\n",
    "print(\"Balanced Accuracy Socre = {:.4f}\".format(bal_accuracy))\n",
    "print(\"True Positive Rate = {:.4f}\".format(TPR))\n",
    "print(\"True Negative Rate = {:.4f}\".format(TNR))\n",
    "print(\"Precision = {:.4f}\".format(Precision))\n",
    "print(\"F1-score = {:.4f}\".format(F1score))\n",
    "print(\"AUC = {:.4f}\\n\".format(roc_auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In genearl, we find that cross-validation helps us to improve the model.  It generally improves the accuracy, balanced accuracy, F1-ratio and AUC.  Overall, the LDA classifier with the best shrinkage parameter appears to perform the best, with an AUC of 0.9334"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
